{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "enigma-codefest-machine-learning.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/gowtham91m/Analytics_Vidhya_hackathon/blob/master/enigma_codefest_machine_learning.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "b1P1FO68Yqb6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement** \n",
        "\n",
        "Date : Aug 30 2018 \n",
        "\n",
        "An online question and answer platform has hired you as a data scientist to identify the best question authors on the platform. This\n",
        "identification will bring more insight into increasing the user engagement. Given the tag of the question, number of views received,\n",
        "number of answers, username and reputation of the question author, the problem requires you to predict the upvote count that the\n",
        "question will receive.\n",
        "\n",
        "Linear model fitted with 3 degree polynomial features did good job on leader board and got me 14 th rank although variance is seen high in the cross validatoin score.\n"
      ]
    },
    {
      "metadata": {
        "id": "NU6fkoqYAYqn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split,GridSearchCV,RandomizedSearchCV\n",
        "from sklearn.linear_model import LinearRegression, RidgeCV, Ridge,LassoCV, Lasso\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import mean_squared_error, r2_score, make_scorer\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from google.colab import files\n",
        "#from sklearn.cross_validation import *\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from time import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ib7np_76BFCJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VHkcFo72BG7N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train = drive.CreateFile({'id': '10ihNrtkuPvwlVEODXmw9N2etRWBxTdmh'})\n",
        "test = drive.CreateFile({'id': '10XhWYDZZYiW0jx8tzj0iijKiEFwUXTrk'})\n",
        "\n",
        "train.GetContentFile('train.csv')\n",
        "test.GetContentFile('test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J0WkUaRZBcCu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')\n",
        "train_id = train.ID\n",
        "test_id = test.ID\n",
        "data = train.append(test)\n",
        "\n",
        "dummies = pd.get_dummies(data.Tag,drop_first=True)\n",
        "data = pd.concat([data,dummies],axis=1)\n",
        "#data.Answers=np.log(data.Answers+1)\n",
        "#data.Reputation=np.log(data.Reputation+1)\n",
        "# drop username\n",
        "data.drop(['ID','Username','Tag'],axis=1,inplace=True)\n",
        "\n",
        "train = data.loc[~data.Upvotes.isnull()]\n",
        "test=data.loc[data.Upvotes.isnull()]\n",
        "test = test.drop(['Upvotes'],axis=1)\n",
        "\n",
        "y = train.Upvotes\n",
        "X = train.drop(['Upvotes'],axis=1)\n",
        "\n",
        "#X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.33, random_state=42)\n",
        "#dtrain = xgb.DMatrix(X_train, label=y_train)\n",
        "#dtest = xgb.DMatrix(X_test, label=y_test)\n",
        "#dtrain = xgb.DMatrix(X,y)\n",
        "#test_matrix = xgb.DMatrix(test)\n",
        "#Std = StandardScaler().fit(X)\n",
        "#X = Std.transform(X)\n",
        "#X_test = Std.transform(test)\n",
        "\n",
        "poly3 = PolynomialFeatures(degree=3)\n",
        "x_poly3 = poly3.fit_transform(X)\n",
        "test_poly3 = poly3.fit_transform(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "utoCIL_jYTTJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sB8liB8ggKa9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def submit_file(model):\n",
        "  pred = model.predict(test_poly3)\n",
        "  submit = pd.DataFrame({'ID':test_id,'Upvotes':pred})\n",
        "  submit.to_csv('submit.csv',index=False)\n",
        "  files.download('submit.csv')\n",
        "\n",
        "## grid search cv\n",
        "def gridsearchcv(xtrain,ytrain,model,params, scoring = None, fit_params = None):\n",
        "  grid = GridSearchCV(model\n",
        "                      ,params\n",
        "                      ,scoring = scoring\n",
        "                      ,fit_params = fit_params\n",
        "                     # ,cv=StratifiedKFold(ytrain, n_folds=2,  shuffle=True)\n",
        "                      ,cv = 4\n",
        "                      ,verbose = 1\n",
        "                      ,refit=True)\n",
        "  grid.fit(xtrain,ytrain)\n",
        "  \n",
        "  best_parameters, score, _ = max(grid.grid_scores_, key=lambda x: x[1])\n",
        "  print('Score:', np.sqrt(-score))\n",
        "  for param_name in sorted(best_parameters.keys()):\n",
        "      print(\"%s: %r\" % (param_name, best_parameters[param_name]))\n",
        "  return grid\n",
        "\n",
        "def randomizedcv(xtrain,ytrain,model,params, scoring = None, fit_params = None):\n",
        "  grid = RandomizedSearchCV(model, params, \n",
        "                   n_jobs=5, \n",
        "                   cv=3, \n",
        "                   scoring=scoring,\n",
        "                   verbose=1,\n",
        "                   refit=True)\n",
        "  grid.fit(xtrain,ytrain)\n",
        "  \n",
        "  best_parameters, score, _ = max(grid.grid_scores_, key=lambda x: x[1])\n",
        "  print('score:', np.sqrt(-score))\n",
        "  for param_name in sorted(best_parameters.keys()):\n",
        "      print(\"%s: %r\" % (param_name, best_parameters[param_name]))\n",
        "  return grid"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vHg9ESQeZ9Sx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ffe050d1-bdd4-410d-8c78-db4bd7020005"
      },
      "cell_type": "code",
      "source": [
        "cvs = cross_val_score(LinearRegression(),x_poly3,y,cv=3,scoring = 'neg_mean_squared_error')\n",
        "cvs = [np.sqrt(-i) for i in cvs]\n",
        "print(cvs)\n",
        "\n",
        "#lr =  LinearRegression().fit(x_poly3,y)\n",
        "#submit_file(lr_poly3)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2122.3850820371536, 964.1365173429301, 1210.9512664271151]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "P0R1p910nikG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M2yhJ7bS4Xvo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "db633f0c-573f-4f96-8dfc-85109f315ac0"
      },
      "cell_type": "code",
      "source": [
        "# solve no space left on the device error\n",
        "%env JOBLIB_TEMP_FOLDER=/tmp"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "env: JOBLIB_TEMP_FOLDER=/tmp\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5i7ILSVY5dl7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "outputId": "44610e60-a013-4e9c-b1de-2013752363e4"
      },
      "cell_type": "code",
      "source": [
        "# xbg\n",
        "params = {'min_child_weight':[4,5], \n",
        "          'gamma':[i/10.0 for i in range(3,6)],  \n",
        "          'subsample':[i/10.0 for i in range(6,11)],\n",
        "          'colsample_bytree':[i/10.0 for i in range(6,11)],\n",
        "          'max_depth': [2,3,4]}\n",
        "\n",
        "xgb = XGBRegressor()\n",
        "model = randomizedcv(x_poly2,y,xgb,params,'neg_mean_squared_error')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=5)]: Done  30 out of  30 | elapsed: 16.6min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "score: 1232.8356240681817\n",
            "colsample_bytree: 0.6\n",
            "gamma: 0.3\n",
            "max_depth: 4\n",
            "min_child_weight: 4\n",
            "subsample: 0.9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:762: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}